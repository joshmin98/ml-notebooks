{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>CSCI-467 Discussion (Week 9)</h1></center>\n",
    "<br>\n",
    "<center><font size=\"4\">Review Session</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intepretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\cdots + \\beta_p x_p$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\beta_0$ is the average value of $\\hat{y}$ that cannot be explained by chosen predictors;\n",
    "- $\\beta_i\\ (i = 1 \\cdots p)$ is the average change of $\\hat{y}$ when there is a one-unit change on $x_i$ and other predictors are fixed (If $x_i$ is dummy variable, then refine this intepretation based on the level of the dummy variable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypothesis Test and Confidence Interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remember the degree of freedom concept in hypothesis test (The T-test and F-test);\n",
    "- T-test: T-distribution is symmetric, so the threshold is $t_{df,\\ \\alpha / 2}$;\n",
    "- F-test: F-distribution is asymmetric, so the threshold is $F_{df1,\\ df2,\\ \\alpha}$;\n",
    "- Confidence interval of coefficients: when sample size is small (e.g. $n < 30$), then we have to construct a t statistic to find the final confidence interval, i.e. let\n",
    "\n",
    "$$Pr\\Bigg(\\left|\\dfrac{\\hat{\\beta_i} - \\beta_i}{SE\\big(\\hat{\\beta_i}\\big)}\\right|\\Bigg) = 1 - \\alpha$$\n",
    "\n",
    "&emsp;&emsp;&nbsp;then we have:\n",
    "\n",
    "$$\\left|\\dfrac{\\hat{\\beta_i} - \\beta_i}{SE\\big(\\hat{\\beta_i}\\big)}\\right| \\leq t_{n - p - 1,\\ \\alpha / 2}$$\n",
    "\n",
    "&emsp;&emsp;&nbsp;do transformation, and we will get the final confidence interval of $\\beta_i$:\n",
    "\n",
    "$$\\left[\\hat{\\beta_i} - t_{n-p-1,\\ \\alpha/2} \\cdot SE\\big(\\hat{\\beta_i}\\big),\\ \\hat{\\beta_i} + t_{n-p-1,\\ \\alpha/2} \\cdot SE\\big(\\hat{\\beta_i}\\big)\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification (Logistic Regression, LDA and Naive Bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remeber how to find the decision boundary (Finding the decision boundary of other forms of $Pr\\big(Y = 1 | X = x\\big)$, such as question 2c in problem set 3, can be inspired by the way shown below). Let\n",
    "\n",
    "$$P\\big(x\\big) = Pr\\big(Y = 1 | X = x\\big) = 0.5$$\n",
    "\n",
    "&emsp;&emsp;&nbsp;then we have \n",
    "\n",
    "$$log\\Bigg(\\dfrac{P\\big(x\\big)}{1 - P\\big(x\\big)}\\Bigg) = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remember how to find the discriminant score $\\delta_k\\big(x\\big)$;\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\delta_k\\big(x\\big)\n",
    "&\\Leftrightarrow argmax\\ p_k\\big(x\\big)  \\\\\n",
    "&\\Leftrightarrow argmax\\ \\dfrac{\\pi_k f_k\\big(x\\big)}{\\sum_{l=1}^{K}\\pi_l f_l\\big(x\\big)} \\\\\n",
    "&\\Leftrightarrow argmax\\ \\pi_k f_k\\big(x\\big) \\\\\n",
    "&\\Leftrightarrow argmax\\ \\bigg(x \\cdot \\dfrac{\\mu_k}{\\sigma_k} - \\dfrac{\\mu_k^2}{2 \\sigma_k} + log\\big(\\pi_k\\big) \\bigg)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "- Decision Boundary (Binary Classification). Let\n",
    "\n",
    "$$\\delta_{k1}\\big(x\\big) = \\delta_{k2}\\big(x\\big)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The following formula is the key point behind Naive Bayes classifier:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Pr\\big(B|A\\big)\n",
    "&= \\dfrac{Pr\\big(A, B\\big)}{Pr\\big(A\\big)}\\\\\n",
    "&= \\dfrac{Pr\\big(A|B\\big) Pr\\big(B\\big)}{\\sum_{l=1}^{K}Pr\\big(A|B_l\\big)Pr\\big(B_l\\big)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "&emsp;&emsp;&nbsp;P.S. The transformation of the denominator is based on the total probability rule.\n",
    "\n",
    "\n",
    "> We do not know the relationship that whether event B will happen given \"A happens\", but we infer their relationship by observing how many times \"A happens\" given \"B happens\". If the value of our observation is high, then we can be more confident to say that when B happens, then the probability of \"A happens\" will be high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The right way and the wrong way to do the cross-validation (We are using cross-validation to test the average performance of the way that used for building a model).\n",
    "\n",
    "> Taking the example from the slides, the way we build the classification model is devided into two steps:\n",
    ">\n",
    "> 1. Starting with 5000 predictors and 50 samples, find the 100 predictors having the largest correlation with the class labels; \n",
    "> 2. We then apply a classifier such as logistic regression, using only these 100 predictors.\n",
    ">\n",
    "> So the first step should be included in cross-validation. Otherwise, the coclusion of the average performation of the built model will be wrong."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
